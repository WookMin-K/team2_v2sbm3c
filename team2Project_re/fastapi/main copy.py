from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from pydantic import BaseModel
import os
import json
import re
import openai
from openai import OpenAI
from typing import List

from sqlalchemy.orm import Session
from db import SessionLocal
from models import User, ChatHistory, Base

# LangChain imports
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from rag_utils import get_vectorstore
from langchain.prompts import PromptTemplate

# 1) DB ì¢…ì†ì„±
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# âœ… .env ë¡œë“œ
load_dotenv()

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
print("âœ… API KEY (repr):", repr(OPENAI_API_KEY))
openai.api_key = OPENAI_API_KEY
client = OpenAI(api_key=OPENAI_API_KEY)


# 1) vectorstore ì´ˆê¸°í™”
vectorstore = get_vectorstore()
# 2) RetrievalQA ì²´ì¸ ìƒì„±
# â€œContextì— ìˆëŠ” ë‚´ìš©ë§Œ ì°¸ê³ â€ í•˜ë¼ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
template = """
ì•„ë˜ 'Context'ì— ìˆëŠ” ë‚´ìš©ë§Œ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— **ì •í™•í•˜ê²Œ** ë‹µí•´ì£¼ì„¸ìš”.
 Context:
 {context}

 ì§ˆë¬¸:
 {question}

 â€» Contextì— ë‹µì´ ì—†ë‹¤ë©´, 'ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë‹µí•´ì£¼ì„¸ìš”.
 """

prompt = PromptTemplate(
    template=template,
    input_variables=["context", "question"]
)

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model_name="gpt-4o", temperature=0),
    chain_type="stuff",
    retriever=vectorstore.as_retriever(),
    chain_type_kwargs={"prompt": prompt},
)
# âœ… FastAPI ì•± ìƒì„±
app = FastAPI()

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://121.78.128.95:3000"],         # or ["http://localhost:3000"] for local dev only
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# âœ… ğŸ“Œ ëª¨ë¸ ì •ì˜
class DateRange(BaseModel):
    start: str
    end: str

class Spot(BaseModel):
    id: int
    name: str
    contenttypeid: int
    lat: float
    lng: float

class ScheduleRequest(BaseModel):
    dateRange: DateRange
    spots: list[Spot]
    departure: str
    transport: str
    persons: int
    
class ChatRequest(BaseModel):
    user_no: int | None       # guest ë©´ None
    user_name: str | None     # guest ë©´ None
    query: str
    
class ChatHistoryItem(BaseModel):
    role: str
    content: str
    created_at: str

# âœ… ğŸ“Œ GPT Prompt ìƒì„± í•¨ìˆ˜
def create_prompt(request: ScheduleRequest) -> str:
    mapping_info = """
contenttypeid ì˜ë¯¸:
- 12: ê´€ê´‘ì§€
- 32: ìˆ™ë°•
- 39: ë§›ì§‘
"""

    prompt = f"""
ë„ˆëŠ” ì—¬í–‰ ì¼ì • ì „ë¬¸ê°€ì•¼.
ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•´ ì¤˜.

âœ… ì¡°ê±´:
- ë§¨ì²˜ìŒ ì¼ì •ì€ {request.departure} ì—ì„œ ì¶œë°œí•˜ëŠ”ê±¸ë¡œ í•´ì¤˜ 
- ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´. ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ ì¶”ê°€ ê¸ˆì§€.
- ë§›ì§‘ì€ 11:00~13:00 ì‹œê°„ëŒ€ì— ë°°ì¹˜
- ìˆ™ë°•ì€ í•˜ë£¨ ë§ˆì§€ë§‰ ì¼ì •
- ë™ì„ ì„ ìµœì†Œí™”
- ì—¬í–‰ì¼ìˆ˜ëŠ” {request.dateRange.start} ~ {request.dateRange.end}
- ì—¬í–‰ ë§ˆì§€ë§‰ ì¼ì •ì€ {request.departure} ë¡œ ëŒì•„ê°€ê²Œ í•´ì¤˜ 

âœ… contenttypeid ë§¤í•‘
{mapping_info}

âœ… ì¥ì†Œ ë°ì´í„°
{request.spots}

âœ… ì¶œë°œì§€
{request.departure}

âœ… ì´ë™ìˆ˜ë‹¨
{request.transport}

âœ… ì¸ì› ìˆ˜
{request.persons}

âœ… ì¶œë ¥ ì˜ˆì‹œ (ë°˜ë“œì‹œ ì´ êµ¬ì¡°ë¡œ ì¶œë ¥):
{{
  "days": [
    {{
      "date": "2024-07-01",
      "schedule": [
        {{"time":"09:00","place":"ê²½ë³µê¶"}},
        {{"time":"11:30","place":"í•´ì¥êµ­ì§‘"}},
        {{"time":"20:00","place":"í˜¸í…”"}}
      ]
    }}
  ]
}}
"""
    return prompt


# âœ… ğŸ“Œ ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡
@app.post("/api/generate-schedule")
async def generate_schedule(request: ScheduleRequest):
    print("âœ… ë°›ì€ ìš”ì²­ ë°ì´í„°:", request.dict())

    prompt = create_prompt(request)
    print("âœ… ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:", prompt)

    try:
        # GPT í˜¸ì¶œ
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ì—¬í–‰ ì¼ì • ìƒì„± ì „ë¬¸ê°€ì•¼. ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•´."},
                {"role": "user", "content": prompt}
            ]
        )

        # GPT ì‘ë‹µ
        schedule_text = completion.choices[0].message.content
        print("âœ… GPT ì‘ë‹µ:", schedule_text)

        # JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
        match = re.search(r"\{[\s\S]*\}", schedule_text)
        if not match:
            raise ValueError("JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        schedule_json = json.loads(match.group())
        print("âœ… íŒŒì‹±ëœ JSON:", schedule_json)

        return {"schedule": schedule_json}

    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        raise HTTPException(status_code=500, detail="ì¼ì • ìƒì„± ì‹¤íŒ¨ - ì„œë²„ ì‘ë‹µ ì²˜ë¦¬ ì˜¤ë¥˜")

# ëŒ€í™” ì´ë ¥ë§Œ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/chat/history", response_model=List[ChatHistoryItem])
def get_chat_history(user_no: int, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.user_no == user_no).first()
    if not user:
        raise HTTPException(404, "ë“±ë¡ëœ íšŒì›ì´ ì•„ë‹™ë‹ˆë‹¤.")
    rows = (
        db.query(ChatHistory)
          .filter(ChatHistory.user_no == user_no)
          .order_by(ChatHistory.created_at)
          .all()
    )
    return [
        ChatHistoryItem(
            role=row.role,
            content=row.content,
            created_at=row.created_at.isoformat()
        )
        for row in rows
    ]
    
# 4) /api/chat ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/chat")
async def chat(request: ChatRequest, db: Session = Depends(get_db)):
    # â€” ì‚¬ìš©ìÂ·ì´ë ¥ ì¡°íšŒ â€”
    if request.user_no:
        user = db.query(User).filter(User.user_no == request.user_no).first()
        if not user:
            raise HTTPException(404, "ë“±ë¡ëœ íšŒì›ì´ ì•„ë‹™ë‹ˆë‹¤.")
        name = user.name
        past = (
            db.query(ChatHistory)
              .filter(ChatHistory.user_no == request.user_no)
              .order_by(ChatHistory.created_at)
              .all()
        )
    else:
        name = "ì†ë‹˜"
        past = []


    # # 4) ëŒ€í™” ì‹¤í–‰ (history + ì§€ê¸ˆ ì§ˆë¬¸)
    # answer = chat_chain.predict(query=request.query)
    
    # 4) RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
    answer = qa_chain.run(request.query)
    
    # -- íŒŒì¼ì—ë„ ê¸°ë¡ --
    with open("chat_history.txt", "a", encoding="utf-8") as f:
        f.write(f"USER: {request.query}\n")
        f.write(f"AI  : {answer}\n")
        f.write("-" * 40 + "\n")

    # â€” DBì— ìƒˆ ì´ë ¥ ì €ì¥ (íšŒì›ë§Œ) â€”
    if request.user_no:
        db.add(ChatHistory(user_no=request.user_no, role="human", content=request.query))
        db.add(ChatHistory(user_no=request.user_no, role="ai",    content=answer))
        db.commit()

    return {"answer": answer}



    

# âœ… ğŸ“Œ (ì„ íƒ) ì¶”ê°€ ë¼ìš°í„° ë“±ë¡ ì˜ˆì‹œ
try:
    from analyzer.api import router
    app.include_router(router)
except ImportError:
    print("âš ï¸ analyzer.api.router ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¶”ê°€í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
# ë¼ìš°í„° ë“±ë¡
from analyzer.api import router as analysis_router
app.include_router(analysis_router)

from analyzer.keyword_extractor import router as keyword_router
app.include_router(keyword_router)


from analyzer.agent_recommend_api import router as agent_router
app.include_router(agent_router)
for route in app.routes:
    print(f"ğŸ” {route.path} â†’ {route.name}")

# âœ… ìƒˆë¡œ ì¶”ê°€
from translate import router as translate_router
app.include_router(translate_router)


